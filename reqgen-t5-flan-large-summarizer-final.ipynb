{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-19T12:07:30.670272Z",
     "iopub.status.busy": "2026-01-19T12:07:30.669492Z",
     "iopub.status.idle": "2026-01-19T12:07:44.287744Z",
     "shell.execute_reply": "2026-01-19T12:07:44.286804Z",
     "shell.execute_reply.started": "2026-01-19T12:07:30.670240Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai-whisper\n",
    "!pip install -q transformers sentencepiece accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T12:07:44.290625Z",
     "iopub.status.busy": "2026-01-19T12:07:44.290367Z",
     "iopub.status.idle": "2026-01-19T12:08:29.147869Z",
     "shell.execute_reply": "2026-01-19T12:08:29.147172Z",
     "shell.execute_reply.started": "2026-01-19T12:07:44.290597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 12:08:11.387487: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768824491.786236      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768824491.893366      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768824492.691637      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768824492.691678      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768824492.691681      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768824492.691683      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "‚úÖ SmartT5LargeDocumentGenerator class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "## whisper large: flan t5-large: comprehensive : best qlty\n",
    "\n",
    "\"\"\"\n",
    "Smart T5 Abstractive Audio Summarizer\n",
    "Handles ANY audio length (30 seconds to 3+ hours)\n",
    "Uses Google's T5 model with intelligent adaptive summarization\n",
    "\n",
    "and\n",
    "\n",
    "Smart T5 Large Audio to Professional Documents Converter\n",
    "Uses: Whisper Large + FLAN-T5-Large\n",
    "Outputs: BRD, Purchase Order, and other business documents\n",
    "Optimized for Kaggle with GPU acceleration\n",
    "\"\"\"\n",
    "\n",
    "import whisper\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# INSTALLATION (Run in Kaggle first cell):\n",
    "# !pip install -q openai-whisper transformers sentencepiece accelerate\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class SmartT5LargeDocumentGenerator:\n",
    "    \"\"\"\n",
    "    Intelligent T5-based audio summarizer with adaptive length control\n",
    "    Perfect for both short (30 sec) and long (3+ hours) audio \n",
    "    and +\n",
    "    Complete pipeline: Audio ‚Üí T5 Large Summary ‚Üí Professional Documents\n",
    "    Handles: BRD, Purchase Orders, Meeting Minutes, Technical Specs\n",
    "    \"\"\"\n",
    "    # Clear memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    def __init__(self, whisper_model=\"large\", t5_model = \"google/flan-t5-large\"):\n",
    "        \"\"\"\n",
    "        Initialize with T5 model\n",
    "        \n",
    "        Args:\n",
    "            whisper_model: 'tiny', 'base', 'small', 'medium', 'large'\n",
    "            t5_model: Choose from:\n",
    "                - 't5-small' (Fast, 60M params, good for short audio)\n",
    "                - 't5-base' (Balanced, 220M params, recommended)\n",
    "                - 't5-large' (Best quality, 770M params, slower)\n",
    "                - 't5-3b' (Highest quality, 3B params, very slow)\n",
    "                - 'google/flan-t5-base' (Instruction-tuned, excellent)\n",
    "                - 'google/flan-t5-large' (Best instruction-following)\n",
    "        \"\"\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        print(f\"üîß Device: {self.device}\")\n",
    "        \n",
    "        if self.device == \"cuda\":\n",
    "            print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        \n",
    "        \n",
    "        # Load Whisper large\n",
    "        print(f\"\\nüì• Loading Whisper '{whisper_model}'...\")\n",
    "        self.whisper_model = whisper.load_model(whisper_model, device=self.device)\n",
    "        print(\"‚úÖ Whisper Large loaded!\")\n",
    "        \n",
    "        # Load T5\n",
    "        print(f\"\\nüì• Loading T5 '{t5_model}'...\")\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(t5_model, legacy=False)\n",
    "\n",
    "        \n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            t5_model,\n",
    "            dtype=torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "        ).to(self.device)\n",
    "        print(\"‚úÖ T5 loaded!\")\n",
    "        \n",
    "        # Store model type for prefix handling\n",
    "        self.is_flan = \"flan\" in t5_model.lower()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚ú® Smart T5 Audio Summarizer Ready!\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    def transcribe_audio(self, audio_path):\n",
    "        \n",
    "        \"\"\"Transcribe multilingual audio to English\"\"\"\n",
    "        \n",
    "        if not os.path.exists(audio_path):\n",
    "            raise FileNotFoundError(f\"‚ùå File not found: {audio_path}\")\n",
    "        \n",
    "        file_size = os.path.getsize(audio_path) / (1024 * 1024)\n",
    "        print(f\"üéµ Audio: {os.path.basename(audio_path)} ({file_size:.2f} MB)\")\n",
    "        print(f\"‚è≥ Transcribing...\\n\")\n",
    "        \n",
    "        result = self.whisper_model.transcribe(\n",
    "            audio_path,\n",
    "            task='translate',\n",
    "            language=None,\n",
    "            fp16=self.device == \"cuda\",\n",
    "            verbose=False,\n",
    "            beam_size=5,\n",
    "            best_of=5,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        lang_map = {\n",
    "            'hi': 'Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)',\n",
    "            'en': 'English',\n",
    "            'mr': 'Marathi (‡§Æ‡§∞‡§æ‡§†‡•Ä)'\n",
    "        }\n",
    "        \n",
    "        detected = result.get('language', 'unknown')\n",
    "        text = result['text'].strip()\n",
    "        word_count = len(text.split())\n",
    "        \n",
    "        print(f\"‚úÖ Transcription complete!\")\n",
    "        print(f\"üåç Language: {lang_map.get(detected, detected)}\")\n",
    "        print(f\"üìù Words: {word_count}\")\n",
    "        #print(f\"üìè Characters: {len(text)}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'language': detected,\n",
    "            'language_name': lang_map.get(detected, detected),\n",
    "            'word_count': word_count\n",
    "        }\n",
    "    \n",
    "    def calculate_adaptive_summary_length(self, word_count, strategy):\n",
    "        \"\"\"\n",
    "        Intelligent adaptive summary length calculation\n",
    "        Optimized for T5 model (works for ANY audio length)\n",
    "        \n",
    "        Args:\n",
    "            word_count: Number of words in transcription\n",
    "            strategy: 'ultra_concise', 'concise', 'balanced', 'detailed', 'comprehensive'\n",
    "        \n",
    "        Returns:\n",
    "            dict with recommended parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        # T5-optimized strategies\n",
    "        strategies = {\n",
    "            'ultra_concise': {\n",
    "                'base_ratio': 0.12,\n",
    "                'min_words': 12,\n",
    "                'max_words': 60,\n",
    "                'description': 'Single sentence summaries'\n",
    "            },\n",
    "            'concise': {\n",
    "                'base_ratio': 0.20,\n",
    "                'min_words': 20,\n",
    "                'max_words': 100,\n",
    "                'description': 'Brief, punchy summaries'\n",
    "            },\n",
    "            'balanced': {\n",
    "                'base_ratio': 0.30,\n",
    "                'min_words': 30,\n",
    "                'max_words': 180,\n",
    "                'description': 'Balanced detail and brevity'\n",
    "            },\n",
    "            'detailed': {\n",
    "                'base_ratio': 0.45,\n",
    "                'min_words': 50,\n",
    "                'max_words': 300,\n",
    "                'description': 'Comprehensive coverage'\n",
    "            },\n",
    "            'comprehensive': {\n",
    "                'base_ratio': 0.60,\n",
    "                'min_words': 80,\n",
    "                'max_words': 450,\n",
    "                'description': 'Extensive detail'\n",
    "            },\n",
    "            # ‚ú® NEW: HYBRID STRATEGY (detailed + comprehensive)\n",
    "            'hybrid': {\n",
    "                'base_ratio': 0.525,  # Average of 0.45 and 0.60\n",
    "                'min_words': 65,      # Average of 50 and 80\n",
    "                'max_words': 375,     # Average of 300 and 450\n",
    "                'description': 'Hybrid: detailed + comprehensive'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        config = strategies.get(strategy, strategies[strategy])\n",
    "        \n",
    "        # Adaptive calculation based on input length\n",
    "        if word_count < 40:\n",
    "            # Very short (< 30 seconds)\n",
    "            max_words = max(config['min_words'], int(word_count * 0.85))\n",
    "            min_words = max(8, int(word_count * 0.5))\n",
    "            ratio = 0.85\n",
    "            \n",
    "        elif word_count < 120:\n",
    "            # Short (30 sec - 1 min)\n",
    "            max_words = max(config['min_words'], int(word_count * 0.65))\n",
    "            min_words = max(12, int(word_count * 0.35))\n",
    "            ratio = 0.65\n",
    "            \n",
    "        elif word_count < 250:\n",
    "            # Medium short (1-2 min)\n",
    "            max_words = int(word_count * 0.50)\n",
    "            min_words = int(word_count * 0.25)\n",
    "            ratio = 0.50\n",
    "            \n",
    "        elif word_count < 600:\n",
    "            # Medium (2-5 min)\n",
    "            max_words = int(word_count * config['base_ratio'])\n",
    "            min_words = int(word_count * (config['base_ratio'] * 0.45))\n",
    "            ratio = config['base_ratio']\n",
    "            \n",
    "        elif word_count < 1500:\n",
    "            # Long (5-15 min)\n",
    "            max_words = int(word_count * (config['base_ratio'] * 0.95))\n",
    "            min_words = int(word_count * (config['base_ratio'] * 0.40))\n",
    "            ratio = config['base_ratio'] * 0.95\n",
    "            \n",
    "        elif word_count < 4000:\n",
    "            # Very long (15-45 min)\n",
    "            max_words = int(word_count * (config['base_ratio'] * 0.85))\n",
    "            min_words = int(word_count * (config['base_ratio'] * 0.35))\n",
    "            ratio = config['base_ratio'] * 0.85\n",
    "            \n",
    "        else:\n",
    "            # Extra long (45+ min)\n",
    "            max_words = int(word_count * (config['base_ratio'] * 0.75))\n",
    "            min_words = int(word_count * (config['base_ratio'] * 0.30))\n",
    "            ratio = config['base_ratio'] * 0.75\n",
    "        \n",
    "        # Apply strategy limits\n",
    "        max_words = min(max_words, config['max_words'])\n",
    "        max_words = max(max_words, config['min_words'])\n",
    "        \n",
    "        min_words = min(min_words, max_words - 8)\n",
    "        min_words = max(min_words, 8)\n",
    "        \n",
    "        # T5 uses tokens (roughly 1 word = 1.5 tokens)\n",
    "        max_tokens = int(max_words * 1.5)\n",
    "        min_tokens = int(min_words * 1.5)\n",
    "        \n",
    "        return {\n",
    "            'max_length': max_tokens,\n",
    "            'min_length': min_tokens,\n",
    "            'max_words': max_words,\n",
    "            'min_words': min_words,\n",
    "            'ratio': ratio,\n",
    "            'strategy': strategy,\n",
    "            'description': config['description']\n",
    "        }\n",
    "    \n",
    "    def generate_t5_summary(\n",
    "        self, \n",
    "        text, \n",
    "        max_length, \n",
    "        min_length, \n",
    "        quality,\n",
    "        custom_instruction=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate abstractive summary using T5\n",
    "        \n",
    "        Args:\n",
    "            text: Input text\n",
    "            max_length: Maximum tokens\n",
    "            min_length: Minimum tokens\n",
    "            quality: 'fast', 'medium', 'high', 'best'\n",
    "            custom_instruction: Optional custom instruction for FLAN-T5\n",
    "        \"\"\"\n",
    "        \n",
    "        # Quality to num_beams mapping\n",
    "        beam_config = {\n",
    "            'fast': 2,\n",
    "            'medium': 4,\n",
    "            'high': 6,\n",
    "            'best': 10\n",
    "        }\n",
    "        num_beams = beam_config.get(quality, 10)\n",
    "        \n",
    "        # Prepare input with T5 prefix\n",
    "        if custom_instruction and self.is_flan:\n",
    "            # FLAN-T5 works better with instructions\n",
    "            input_text = f\"{custom_instruction}: {text}\"\n",
    "        else:\n",
    "            # Standard T5 prefix\n",
    "            input_text = f\"summarize: {text}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512,  # T5 input limit\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Generate summary\n",
    "        with torch.no_grad():\n",
    "            summary_ids = self.model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_length=max_length,\n",
    "                min_length=min_length,\n",
    "                num_beams=num_beams,\n",
    "                length_penalty=1.5,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                repetition_penalty=1.2,\n",
    "                temperature=1.0\n",
    "            )\n",
    "        \n",
    "        # Decode\n",
    "        summary = self.tokenizer.decode(\n",
    "            summary_ids[0],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        \n",
    "        return summary\n",
    "        \n",
    "    def extract_structured_info(self, summary_text):\n",
    "        \n",
    "        \"\"\"Extract structured information from summary\"\"\"\n",
    "        \n",
    "        info = {\n",
    "            'requirements': [],\n",
    "            'decisions': [],\n",
    "            'action_items': [],\n",
    "            'timeline': [],\n",
    "            'budget': [],\n",
    "            'risks': [],\n",
    "            'technical': [],\n",
    "            'deliverables': [],\n",
    "            'stakeholders': []\n",
    "        }\n",
    "        \n",
    "        sentences = re.split(r'[.!?]+', summary_text)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "            \n",
    "            lower = sentence.lower()\n",
    "            \n",
    "            # Requirements\n",
    "            if any(w in lower for w in ['require', 'need', 'must', 'should', 'shall', 'expect']):\n",
    "                info['requirements'].append(sentence)\n",
    "            \n",
    "            # Decisions\n",
    "            if any(w in lower for w in ['decide', 'agreed', 'approved', 'confirmed', 'finalized']):\n",
    "                info['decisions'].append(sentence)\n",
    "            \n",
    "            # Action items\n",
    "            if any(w in lower for w in ['will', 'task', 'action', 'assign', 'responsible', 'owner']):\n",
    "                info['action_items'].append(sentence)\n",
    "            \n",
    "            # Timeline\n",
    "            if any(w in lower for w in ['deadline', 'timeline', 'date', 'week', 'month', 'schedule', 'due']):\n",
    "                info['timeline'].append(sentence)\n",
    "            \n",
    "            # Budget\n",
    "            if any(w in lower for w in ['cost', 'budget', 'price', 'payment', 'fund', 'expense', '$', 'rs', 'rupee', 'inr']):\n",
    "                info['budget'].append(sentence)\n",
    "            \n",
    "            # Risks\n",
    "            if any(w in lower for w in ['risk', 'concern', 'issue', 'challenge', 'problem', 'blocker']):\n",
    "                info['risks'].append(sentence)\n",
    "            \n",
    "            # Technical\n",
    "            if any(w in lower for w in ['technical', 'technology', 'system', 'platform', 'api', 'database', 'infrastructure']):\n",
    "                info['technical'].append(sentence)\n",
    "            \n",
    "            # Deliverables\n",
    "            if any(w in lower for w in ['deliver', 'output', 'product', 'feature', 'component', 'milestone']):\n",
    "                info['deliverables'].append(sentence)\n",
    "            \n",
    "            # Stakeholders\n",
    "            if any(w in lower for w in ['stakeholder', 'team', 'department', 'client', 'customer', 'vendor']):\n",
    "                info['stakeholders'].append(sentence)\n",
    "        \n",
    "        return info\n",
    "\n",
    "    def generate_brd(self, summary_text, structured_info, metadata):\n",
    "        \"\"\"Generate Business Requirements Document\"\"\"\n",
    "        \n",
    "        doc = f\"\"\"\n",
    "{'='*80}\n",
    "BUSINESS REQUIREMENTS DOCUMENT (BRD)\n",
    "{'='*80}\n",
    "\n",
    "Document Information:\n",
    "--------------------\n",
    "Project Name:     {metadata.get('project_name', 'Audio Extracted Project')}\n",
    "Document Date:    {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\n",
    "Version:          {metadata.get('version', '1.0')}\n",
    "Prepared By:      {metadata.get('author', 'T5 Large Audio Analysis System')}\n",
    "Status:           {metadata.get('status', 'Draft - Extracted from Audio')}\n",
    "Department:       {metadata.get('department', 'TBD')}\n",
    "Sponsor:          {metadata.get('sponsor', 'TBD')}\n",
    "\n",
    "\n",
    "1. EXECUTIVE SUMMARY\n",
    "{'='*80}\n",
    "\n",
    "{summary_text}\n",
    "\n",
    "\n",
    "2. BUSINESS OBJECTIVES\n",
    "{'='*80}\n",
    "\n",
    "Based on the audio discussion, the key business objectives are:\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Add objectives from summary\n",
    "        if structured_info['requirements']:\n",
    "            for idx, req in enumerate(structured_info['requirements'][:5], 1):\n",
    "                doc += f\"OBJ-{idx}: {req}\\n\"\n",
    "        else:\n",
    "            doc += \"Business objectives to be refined based on stakeholder review.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "3. BUSINESS REQUIREMENTS\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['requirements']:\n",
    "            for idx, req in enumerate(structured_info['requirements'], 1):\n",
    "                doc += f\"BR-{idx:03d}: {req}\\n\"\n",
    "                doc += f\"         Priority: {metadata.get('priority', 'Medium')}\\n\"\n",
    "                doc += f\"         Status: New\\n\"\n",
    "                doc += f\"         Source: Audio Discussion\\n\\n\"\n",
    "        else:\n",
    "            doc += \"Business requirements extracted from executive summary above.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "4. FUNCTIONAL REQUIREMENTS\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['technical']:\n",
    "            for idx, tech in enumerate(structured_info['technical'], 1):\n",
    "                doc += f\"FR-{idx:03d}: {tech}\\n\"\n",
    "                doc += f\"         Category: {metadata.get('category', 'Technical')}\\n\"\n",
    "                doc += f\"         Priority: {metadata.get('priority', 'Medium')}\\n\\n\"\n",
    "        else:\n",
    "            doc += \"Functional requirements to be detailed in technical specification.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "5. STAKEHOLDERS\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['stakeholders']:\n",
    "            doc += \"Stakeholders identified in discussion:\\n\\n\"\n",
    "            for stakeholder in structured_info['stakeholders']:\n",
    "                doc += f\"‚Ä¢ {stakeholder}\\n\"\n",
    "        else:\n",
    "            doc += f\"\"\"\n",
    "Primary Stakeholders:\n",
    "‚Ä¢ Project Sponsor: {metadata.get('sponsor', 'TBD')}\n",
    "‚Ä¢ Business Owner: {metadata.get('business_owner', 'TBD')}\n",
    "‚Ä¢ Project Manager: {metadata.get('pm', 'TBD')}\n",
    "‚Ä¢ End Users: {metadata.get('end_users', 'As discussed in audio')}\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "6. KEY DECISIONS\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['decisions']:\n",
    "            for idx, decision in enumerate(structured_info['decisions'], 1):\n",
    "                doc += f\"D{idx}. {decision}\\n\"\n",
    "                doc += f\"    Date: {metadata.get('date', 'TBD')}\\n\"\n",
    "                doc += f\"    Decision Maker: {metadata.get('decision_maker', 'TBD')}\\n\\n\"\n",
    "        else:\n",
    "            doc += \"Key decisions documented in executive summary.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "7. SCOPE\n",
    "{'='*80}\n",
    "\n",
    "In Scope:\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['deliverables']:\n",
    "            for deliverable in structured_info['deliverables']:\n",
    "                doc += f\"‚Ä¢ {deliverable}\\n\"\n",
    "        else:\n",
    "            doc += \"‚Ä¢ As defined in requirements above\\n\"\n",
    "        \n",
    "        doc += \"\"\"\n",
    "\n",
    "Out of Scope:\n",
    "‚Ä¢ Items not mentioned in the audio discussion\n",
    "‚Ä¢ Features to be considered for future phases\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "8. TIMELINE & MILESTONES\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['timeline']:\n",
    "            for milestone in structured_info['timeline']:\n",
    "                doc += f\"‚Ä¢ {milestone}\\n\"\n",
    "        else:\n",
    "            doc += f\"\"\"\n",
    "Project Timeline:\n",
    "‚Ä¢ Requirements Phase: {metadata.get('req_phase', 'TBD')}\n",
    "‚Ä¢ Design Phase: {metadata.get('design_phase', 'TBD')}\n",
    "‚Ä¢ Development Phase: {metadata.get('dev_phase', 'TBD')}\n",
    "‚Ä¢ Testing Phase: {metadata.get('test_phase', 'TBD')}\n",
    "‚Ä¢ Deployment: {metadata.get('deployment', 'TBD')}\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "9. BUDGET & RESOURCES\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['budget']:\n",
    "            for budget_item in structured_info['budget']:\n",
    "                doc += f\"‚Ä¢ {budget_item}\\n\"\n",
    "        else:\n",
    "            doc += f\"\"\"\n",
    "Estimated Budget: {metadata.get('budget', 'To be determined')}\n",
    "\n",
    "Resource Requirements:\n",
    "‚Ä¢ Team Size: {metadata.get('team_size', 'TBD')}\n",
    "‚Ä¢ Duration: {metadata.get('duration', 'TBD')}\n",
    "‚Ä¢ External Resources: {metadata.get('external_resources', 'TBD')}\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "10. RISKS & ASSUMPTIONS\n",
    "{'='*80}\n",
    "\n",
    "Risks Identified:\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['risks']:\n",
    "            for idx, risk in enumerate(structured_info['risks'], 1):\n",
    "                doc += f\"{idx}. {risk}\\n\"\n",
    "                doc += f\"   Impact: {metadata.get('risk_impact', 'Medium')}\\n\"\n",
    "                doc += f\"   Mitigation: To be defined\\n\\n\"\n",
    "        else:\n",
    "            doc += \"Risk assessment to be conducted during project planning.\\n\"\n",
    "        \n",
    "        doc += \"\"\"\n",
    "\n",
    "Assumptions:\n",
    "‚Ä¢ Resources will be available as per project timeline\n",
    "‚Ä¢ Stakeholder approvals will be obtained in timely manner\n",
    "‚Ä¢ Technical infrastructure is available and ready\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "11. DEPENDENCIES\n",
    "{'='*80}\n",
    "\n",
    "‚Ä¢ Dependencies identified in audio discussion\n",
    "‚Ä¢ External systems and integrations as required\n",
    "‚Ä¢ Third-party services and vendors as needed\n",
    "\n",
    "\n",
    "12. SUCCESS CRITERIA\n",
    "{'='*80}\n",
    "\n",
    "The project will be considered successful when:\n",
    "\n",
    "‚Ä¢ All business requirements are met\n",
    "‚Ä¢ System is deployed and operational\n",
    "‚Ä¢ User acceptance testing is completed successfully\n",
    "‚Ä¢ Stakeholders sign off on deliverables\n",
    "\n",
    "\n",
    "13. APPROVAL\n",
    "{'='*80}\n",
    "\n",
    "This document has been reviewed and approved by:\n",
    "\n",
    "\n",
    "Business Owner: _____________________    Date: ___________\n",
    "\n",
    "Signature:      _____________________\n",
    "\n",
    "\n",
    "Project Sponsor: ____________________    Date: ___________\n",
    "\n",
    "Signature:       ____________________\n",
    "\n",
    "\n",
    "{'='*80}\n",
    "Document Generated from Audio Analysis using Whisper Large + FLAN-T5 Large\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "        \n",
    "        return doc\n",
    "    \n",
    "    def generate_purchase_order(self, summary_text, structured_info, metadata):\n",
    "        \"\"\"Generate Purchase Order\"\"\"\n",
    "        \n",
    "        doc = f\"\"\"\n",
    "{'='*80}\n",
    "PURCHASE ORDER\n",
    "{'='*80}\n",
    "\n",
    "PO Number:        {metadata.get('po_number', 'PO-' + datetime.now().strftime('%Y%m%d-%H%M'))}\n",
    "Date:             {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\n",
    "Status:           {metadata.get('status', 'Draft - Extracted from Audio')}\n",
    "\n",
    "\n",
    "VENDOR INFORMATION:\n",
    "{'='*80}\n",
    "Vendor Name:      {metadata.get('vendor_name', 'TBD - As per audio discussion')}\n",
    "Vendor Code:      {metadata.get('vendor_code', 'TBD')}\n",
    "Address:          {metadata.get('vendor_address', 'TBD')}\n",
    "City/State/ZIP:   {metadata.get('vendor_location', 'TBD')}\n",
    "Contact Person:   {metadata.get('vendor_contact', 'TBD')}\n",
    "Phone:            {metadata.get('vendor_phone', 'TBD')}\n",
    "Email:            {metadata.get('vendor_email', 'TBD')}\n",
    "GST/Tax ID:       {metadata.get('vendor_gst', 'TBD')}\n",
    "\n",
    "\n",
    "BUYER INFORMATION:\n",
    "{'='*80}\n",
    "Company Name:     {metadata.get('company_name', 'Your Company Ltd.')}\n",
    "Department:       {metadata.get('department', 'Procurement')}\n",
    "Address:          {metadata.get('buyer_address', 'TBD')}\n",
    "City/State/ZIP:   {metadata.get('buyer_location', 'TBD')}\n",
    "Contact Person:   {metadata.get('buyer_contact', metadata.get('author', 'TBD'))}\n",
    "Phone:            {metadata.get('buyer_phone', 'TBD')}\n",
    "Email:            {metadata.get('buyer_email', 'TBD')}\n",
    "\n",
    "\n",
    "PURCHASE ORDER SUMMARY:\n",
    "{'='*80}\n",
    "\n",
    "Based on Audio Discussion:\n",
    "{summary_text}\n",
    "\n",
    "\n",
    "DETAILED LINE ITEMS:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Extract items from deliverables or requirements\n",
    "        items = structured_info['deliverables'] if structured_info['deliverables'] else structured_info['requirements']\n",
    "        \n",
    "        doc += f\"{'Item':<5} {'Description':<45} {'Qty':<8} {'Unit':<10} {'Price':<12} {'Total':<12}\\n\"\n",
    "        doc += \"-\" * 100 + \"\\n\"\n",
    "        \n",
    "        if items:\n",
    "            for idx, item in enumerate(items[:15], 1):  # Max 15 items\n",
    "                clean_item = item.replace('\\n', ' ')[:42]\n",
    "                doc += f\"{idx:<5} {clean_item:<45} {'TBD':<8} {'Each':<10} {'TBD':<12} {'TBD':<12}\\n\"\n",
    "        else:\n",
    "            doc += f\"{'1':<5} {'Items/Services as per audio discussion':<45} {'TBD':<8} {'Each':<10} {'TBD':<12} {'TBD':<12}\\n\"\n",
    "        \n",
    "        doc += \"\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "COST BREAKDOWN:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['budget']:\n",
    "            doc += \"Cost Details (from audio discussion):\\n\\n\"\n",
    "            for budget_item in structured_info['budget']:\n",
    "                doc += f\"‚Ä¢ {budget_item}\\n\"\n",
    "            doc += \"\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "Subtotal:                                                    {metadata.get('subtotal', 'TBD')}\n",
    "Discount (if any):                                           {metadata.get('discount', '0.00')}\n",
    "                                                             ___________\n",
    "Subtotal after Discount:                                     {metadata.get('subtotal_after_discount', 'TBD')}\n",
    "\n",
    "Tax/GST ({metadata.get('tax_rate', '18')}%):                                             {metadata.get('tax_amount', 'TBD')}\n",
    "Shipping & Handling:                                         {metadata.get('shipping', 'TBD')}\n",
    "Other Charges:                                               {metadata.get('other_charges', '0.00')}\n",
    "                                                             ___________\n",
    "TOTAL AMOUNT:                                                {metadata.get('total_amount', 'TBD')}\n",
    "                                                             ===========\n",
    "\n",
    "\n",
    "TERMS & CONDITIONS:\n",
    "{'='*80}\n",
    "\n",
    "Payment Terms:         {metadata.get('payment_terms', 'Net 30 Days')}\n",
    "Delivery Terms:        {metadata.get('delivery_terms', 'FOB Destination')}\n",
    "Expected Delivery:     {metadata.get('delivery_date', 'TBD - As per discussion')}\n",
    "Delivery Address:      {metadata.get('delivery_address', 'As per buyer information above')}\n",
    "Shipping Method:       {metadata.get('shipping_method', 'Standard')}\n",
    "Warranty:              {metadata.get('warranty', 'As per vendor terms')}\n",
    "Return Policy:         {metadata.get('return_policy', 'As per vendor terms')}\n",
    "\n",
    "\n",
    "PAYMENT SCHEDULE:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if metadata.get('payment_schedule'):\n",
    "            doc += metadata['payment_schedule']\n",
    "        else:\n",
    "            doc += f\"\"\"\n",
    "‚Ä¢ Advance Payment: {metadata.get('advance_payment', '0%')} on PO confirmation\n",
    "‚Ä¢ Balance Payment: {metadata.get('balance_payment', '100%')} {metadata.get('payment_terms', 'Net 30')}\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "SPECIAL INSTRUCTIONS:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['requirements']:\n",
    "            doc += \"Requirements from audio discussion:\\n\\n\"\n",
    "            for req in structured_info['requirements'][:5]:\n",
    "                doc += f\"‚Ä¢ {req}\\n\"\n",
    "        else:\n",
    "            doc += \"As per audio discussion and mutual agreement.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "ADDITIONAL NOTES:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['action_items']:\n",
    "            doc += \"Action Items:\\n\\n\"\n",
    "            for action in structured_info['action_items'][:5]:\n",
    "                doc += f\"‚Ä¢ {action}\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "VALIDITY:\n",
    "{'='*80}\n",
    "\n",
    "This Purchase Order is valid until: {metadata.get('validity_date', 'TBD')}\n",
    "\n",
    "\n",
    "APPROVAL & AUTHORIZATION:\n",
    "{'='*80}\n",
    "\n",
    "Requested By:\n",
    "\n",
    "Name:      {metadata.get('requested_by', 'TBD')}\n",
    "Title:     {metadata.get('requested_title', 'TBD')}\n",
    "Date:      {metadata.get('date', 'TBD')}\n",
    "Signature: _____________________\n",
    "\n",
    "\n",
    "Approved By:\n",
    "\n",
    "Name:      {metadata.get('approved_by', 'TBD')}\n",
    "Title:     {metadata.get('approved_title', 'Manager/Director')}\n",
    "Date:      ___________\n",
    "Signature: _____________________\n",
    "\n",
    "\n",
    "Finance Approval:\n",
    "\n",
    "Name:      {metadata.get('finance_approval', 'TBD')}\n",
    "Title:     Finance Manager\n",
    "Date:      ___________\n",
    "Signature: _____________________\n",
    "\n",
    "\n",
    "VENDOR ACCEPTANCE:\n",
    "{'='*80}\n",
    "\n",
    "We accept the terms and conditions of this Purchase Order:\n",
    "\n",
    "Vendor Name:    {metadata.get('vendor_name', 'TBD')}\n",
    "Authorized By:  _____________________\n",
    "Title:          _____________________\n",
    "Date:           ___________\n",
    "Signature:      _____________________\n",
    "Company Seal:   \n",
    "\n",
    "\n",
    "{'='*80}\n",
    "Purchase Order Generated from Audio Analysis\n",
    "System: Whisper Large + FLAN-T5 Large\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'='*80}\n",
    "\n",
    "IMPORTANT NOTES:\n",
    "- This is a preliminary document extracted from audio discussion\n",
    "- Please review and verify all details before finalization\n",
    "- TBD items must be filled in before final approval\n",
    "- Consult legal/procurement team for compliance review\n",
    "\"\"\"\n",
    "        \n",
    "        return doc\n",
    "\n",
    "    def process_audio_smart(\n",
    "        self,\n",
    "        audio_path,\n",
    "        strategy,\n",
    "        quality,\n",
    "        custom_instruction=None,\n",
    "        save_output=True,\n",
    "        output_filename=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Complete smart pipeline with T5 adaptive summarization\n",
    "        \n",
    "        Args:\n",
    "            audio_path: Path to audio file\n",
    "            strategy: 'ultra_concise', 'concise', 'balanced', 'detailed', 'comprehensive'\n",
    "            quality: 'fast', 'medium', 'high', 'best'\n",
    "            custom_instruction: Optional instruction for FLAN-T5\n",
    "                               e.g., \"Summarize the key business points\"\n",
    "            save_output: Save results to file\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"üéØ SMART T5 AUDIO SUMMARIZER\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        \n",
    "        # Step 1: Transcribe\n",
    "        transcription = self.transcribe_audio(audio_path)\n",
    "        word_count = transcription['word_count']\n",
    "        \n",
    "        # Step 2: Calculate smart summary length\n",
    "        print(f\"üß† Calculating adaptive summary length...\")\n",
    "        summary_config = self.calculate_adaptive_summary_length(word_count, strategy)\n",
    "        \n",
    "        print(f\"üìä Strategy: {summary_config['strategy'].upper()}\")\n",
    "        print(f\"üìù Description: {summary_config['description']}\")\n",
    "        print(f\"üìè Input: {word_count} words\")\n",
    "        print(f\"üìè Target: {summary_config['min_words']}-{summary_config['max_words']} words\")\n",
    "        print(f\"üìâ Compression: {summary_config['ratio']*100:.0f}%\")\n",
    "        print(f\"‚ö° Quality: {quality.upper()}\\n\")\n",
    "        \n",
    "        if custom_instruction:\n",
    "            print(f\"üí¨ Custom Instruction: {custom_instruction}\\n\")\n",
    "        \n",
    "        # Step 3: Handle very short text\n",
    "        if word_count < 25:\n",
    "            print(\"‚ö†Ô∏è Text very short (<25 words) - returning full transcription\\n\")\n",
    "            summary = transcription['text']\n",
    "            summary_words = word_count\n",
    "        \n",
    "        # Step 4: Summarize with T5\n",
    "        else:\n",
    "            print(f\"üìä Generating T5 summary (process_audio_smart)...\")\n",
    "            \n",
    "            # For long texts, use chunking\n",
    "            if word_count > 400:\n",
    "                summary = self._summarize_long_text(\n",
    "                    transcription['text'],\n",
    "                    summary_config,\n",
    "                    quality,\n",
    "                    custom_instruction\n",
    "                )\n",
    "            else:\n",
    "                summary = self.generate_t5_summary(\n",
    "                    transcription['text'],\n",
    "                    max_length=summary_config['max_length'],\n",
    "                    min_length=summary_config['min_length'],\n",
    "                    quality=quality,\n",
    "                    custom_instruction=custom_instruction\n",
    "                )\n",
    "            \n",
    "            summary_words = len(summary.split())\n",
    "            print(f\"‚úÖ Summary generated! ({summary_words} words)\\n\")\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            'audio_file': os.path.basename(audio_path),\n",
    "            'language': transcription['language_name'],\n",
    "            'transcription': transcription['text'],\n",
    "            'summary': summary,\n",
    "            'input_words': word_count,\n",
    "            'summary_words': summary_words,\n",
    "            'compression_ratio': (1 - summary_words/word_count) * 100 if word_count > 0 else 0,\n",
    "            'strategy': strategy,\n",
    "            'quality': quality,\n",
    "            'config': summary_config,\n",
    "            'custom_instruction': custom_instruction\n",
    "        }\n",
    "\n",
    "    # Display results\n",
    "        self._display_results(results)\n",
    "    \n",
    "    # Save results\n",
    "        if save_output:\n",
    "            self._save_results(results, custom_filename=output_filename)\n",
    "    \n",
    "    # ‚úÖ ADD THIS: Return the results!\n",
    "        return results\n",
    "\n",
    "    def process_audio_to_document(\n",
    "        self,\n",
    "        audio_path,           \n",
    "        summary_text,\n",
    "        document_type='brd',\n",
    "        custom_instruction=None,\n",
    "        metadata=None,\n",
    "        save_output=True,\n",
    "        output_filename=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Complete pipeline: not Audio ‚Üí Summary ‚Üí Document\n",
    "        \n",
    "        Args:\n",
    "            audio_path: Path to audio file\n",
    "            document_type: 'brd' or 'purchase_order'\n",
    "            custom_instruction: Custom instruction for T5\n",
    "            metadata: Document metadata\n",
    "        \n",
    "        Returns:\n",
    "            dict with transcription, summary, and formatted document\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(f\"AUDIO TO {document_type.upper()} CONVERTER\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        \"\"\" Step 1: Transcribe\n",
    "        print(\"STEP 1: Transcribing with Whisper Large...\")\n",
    "        transcription = self.transcribe_audio(audio_path)\n",
    "        \n",
    "         Step 2: Generate Summary\n",
    "        print(\"STEP 2: Generating summary with FLAN-T5 Large...\")\n",
    "        summary = self.generate_summary(\n",
    "            transcription['text'],\n",
    "            custom_instruction=custom_instruction\n",
    "        \n",
    "\n",
    "        summary = self.process_audio_smart(audio_path,\n",
    "            strategy,\n",
    "            quality,\n",
    "            custom_instruction=None,\n",
    "            save_output=True,\n",
    "            output_filename=None))\"\"\"\n",
    "        \n",
    "        # Step 3: Extract structured information\n",
    "        print(\"STEP 3: Extracting structured information...\")\n",
    "        structured_info = self.extract_structured_info(summary_text)\n",
    "        \n",
    "        # Step 4: Generate document\n",
    "        print(f\"STEP 4: Generating {document_type.upper()}...\\n\")\n",
    "        \n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "        \n",
    "        metadata.setdefault('project_name', os.path.basename(audio_path).split('.')[0])\n",
    "        metadata.setdefault('date', datetime.now().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        if document_type == 'brd':\n",
    "            formatted_doc = self.generate_brd(summary_text, structured_info, metadata)\n",
    "        elif document_type == 'purchase_order':\n",
    "            formatted_doc = self.generate_purchase_order(summary_text, structured_info, metadata)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown document type: {document_type}\")\n",
    "        \n",
    "        # Step 5: Save\n",
    "        output_filename = f\"/kaggle/working/{document_type}_{metadata['project_name']}.txt\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(formatted_doc)\n",
    "        \n",
    "        print(f\"‚úÖ {document_type.upper()} generated and saved!\")\n",
    "        print(f\"üìÅ File: {output_filename}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'structured_info': structured_info,\n",
    "            'formatted_document': formatted_doc,\n",
    "            'output_file': output_filename\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "    # Display results\n",
    "        self._display_results(results)\n",
    "        \n",
    "        # Save results\n",
    "        if save_output:\n",
    "            self._save_results(results, custom_filename=output_filename)\n",
    "        \n",
    "    \n",
    "    def _summarize_long_text(self, text, summary_config, quality, custom_instruction):\n",
    "        \"\"\"Handle long texts with intelligent chunking\"\"\"\n",
    "        # T5 handles ~400 words well per chunk\n",
    "        chunk_size = 400  # words\n",
    "        words = text.split()\n",
    "        chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "        \n",
    "        print(f\"  üìÑ Processing {len(chunks)} chunk(s)...\")\n",
    "        \n",
    "        chunk_summaries = []\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            chunk_words = len(chunk.split())\n",
    "            \n",
    "            if chunk_words < 25:\n",
    "                continue\n",
    "            \n",
    "            # Adaptive length per chunk\n",
    "            chunk_config = self.calculate_adaptive_summary_length(\n",
    "                chunk_words,\n",
    "                summary_config['strategy']\n",
    "            )\n",
    "            \n",
    "            print(f\"    ‚û§ Chunk {idx+1}/{len(chunks)} ({chunk_words} words)...\", end=\" \")\n",
    "            \n",
    "            try:\n",
    "                chunk_summary = self.generate_t5_summary(\n",
    "                    chunk,\n",
    "                    max_length=chunk_config['max_length'],\n",
    "                    min_length=chunk_config['min_length'],\n",
    "                    quality=quality,\n",
    "                    custom_instruction=custom_instruction\n",
    "                )\n",
    "                chunk_summaries.append(chunk_summary)\n",
    "                print(\"‚úì\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó (Error: {str(e)[:30]})\")\n",
    "                continue\n",
    "        \n",
    "        if not chunk_summaries:\n",
    "            return text[:500]\n",
    "        \n",
    "        combined = ' '.join(chunk_summaries)\n",
    "        combined_words = len(combined.split())\n",
    "        \n",
    "        # Final summary if still too long\n",
    "        if len(chunks) > 1 and combined_words > summary_config['max_words']:\n",
    "            print(f\"  ‚û§ Creating final summary ({combined_words} words)...\", end=\" \")\n",
    "            try:\n",
    "                final = self.generate_t5_summary(\n",
    "                    combined,\n",
    "                    max_length=summary_config['max_length'],\n",
    "                    min_length=summary_config['min_length'],\n",
    "                    quality=quality,\n",
    "                    custom_instruction=custom_instruction\n",
    "                )\n",
    "                print(\"‚úì\")\n",
    "                return final\n",
    "            except:\n",
    "                print(\"‚úó\")\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    def _display_results(self, results):\n",
    "        \"\"\"Display formatted results\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"üìã RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"üìÅ File: {results['audio_file']}\")\n",
    "        print(f\"üåç Language: {results['language']}\")\n",
    "        print(f\"üìä strategy: {results['strategy'].upper()}\")\n",
    "        print(f\"‚ö° Quality: {results['quality'].upper()}\")\n",
    "        if results.get('custom_instruction'):\n",
    "            print(f\"üí¨ Instruction: {results['custom_instruction']}\")\n",
    "        print(f\"üìè Original: {results['input_words']} words\")\n",
    "        print(f\"üìè Summary: {results['summary_words']} words\")\n",
    "        print(f\"üìâ Compression: {results['compression_ratio']:.1f}%\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚ú® T5 ABSTRACTIVE SUMMARY:\")\n",
    "        print(\"=\"*70)\n",
    "        print(results['summary'])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìÑ FULL TRANSCRIPTION (first 400 chars):\")\n",
    "        print(\"=\"*70)\n",
    "        print(results['transcription'][:400] + \"...\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    def _save_results(self, results, custom_filename=None):\n",
    "        \"\"\"Save to file with optional custom filename\"\"\"\n",
    "\n",
    "        # Use custom filename if provided, otherwise use default\n",
    "        if custom_filename:\n",
    "            output_file = f\"/kaggle/working/{custom_filename}\"\n",
    "        else:\n",
    "            output_file = \"/kaggle/working/t5_best_smart_summary.txt\"\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=\"*70 + \"\\n\")\n",
    "            f.write(\"SMART T5 AUDIO SUMMARY REPORT\\n\")\n",
    "            f.write(\"=\"*70 + \"\\n\\n\")\n",
    "            f.write(f\"Audio File: {results['audio_file']}\\n\")\n",
    "            f.write(f\"Language: {results['language']}\\n\")\n",
    "            #f.write(f\"Models: {results['models']}\\n\")\n",
    "            f.write(f\"Strategy: {results['strategy']}\\n\")\n",
    "            f.write(f\"Quality: {results['quality']}\\n\")\n",
    "            if results.get('custom_instruction'):\n",
    "                f.write(f\"Custom Instruction: {results['custom_instruction']}\\n\")\n",
    "            f.write(f\"Original Words: {results['input_words']}\\n\")\n",
    "            f.write(f\"Summary Words: {results['summary_words']}\\n\")\n",
    "            f.write(f\"Compression: {results['compression_ratio']:.1f}%\\n\\n\")\n",
    "            f.write(\"=\"*70 + \"\\n\")\n",
    "            f.write(\"T5 ABSTRACTIVE SUMMARY:\\n\")\n",
    "            f.write(\"=\"*70 + \"\\n\\n\")\n",
    "            f.write(results['summary'] + \"\\n\\n\")\n",
    "            f.write(\"=\"*70 + \"\\n\")\n",
    "            f.write(\"FULL TRANSCRIPTION:\\n\")\n",
    "            f.write(\"=\"*70 + \"\\n\\n\")\n",
    "            f.write(results['transcription'] + \"\\n\")\n",
    "        \n",
    "        print(f\"üíæ Saved to: {output_file}\\n\")\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize with T5 model\n",
    "        \n",
    "        Args:\n",
    "            whisper_model: 'tiny', 'base', 'small', 'medium', 'large'\n",
    "            t5_model: Choose from:\n",
    "                - 't5-small' (Fast, 60M params, good for short audio)\n",
    "                - 't5-base' (Balanced, 220M params, recommended)\n",
    "                - 't5-large' (Best quality, 770M params, slower)\n",
    "                - 't5-3b' (Highest quality, 3B params, very slow)\n",
    "                - 'google/flan-t5-base' (Instruction-tuned, excellent)\n",
    "                - 'google/flan-t5-large' (Best instruction-following)\n",
    "\n",
    "            Args:\n",
    "            word_count: Number of words in transcription\n",
    "            strategy: 'ultra_concise', 'concise', 'balanced', 'detailed', 'comprehensive'\n",
    "        \n",
    "        \"\"\"\n",
    "# Test that class is defined\n",
    "print(\"\\n\\n‚úÖ SmartT5LargeDocumentGenerator class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T12:08:29.149267Z",
     "iopub.status.busy": "2026-01-19T12:08:29.148784Z",
     "iopub.status.idle": "2026-01-19T12:12:42.820409Z",
     "shell.execute_reply": "2026-01-19T12:12:42.819753Z",
     "shell.execute_reply.started": "2026-01-19T12:08:29.149243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALIZING T5 LARGE DOCUMENT GENERATOR\n",
      "======================================================================\n",
      "\n",
      "üîß Device: cuda\n",
      "üöÄ GPU: Tesla T4\n",
      "üíæ GPU Memory: 15.83 GB\n",
      "\n",
      "üì• Loading Whisper 'large'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.88G/2.88G [00:26<00:00, 117MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Whisper Large loaded!\n",
      "\n",
      "üì• Loading T5 'google/flan-t5-large'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c6cdcb578041daa66bf50a5b308191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad9db1361734a0a886576b3998aee2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134c495cad3949f28efdca79fb7c6969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e97bd525b4c40909e97dcc4056e75aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba82a8a60854d9a8da6163375ef3435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57671145e66645e5a44f3f9028c0c35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9118ff3b55404637b72a548bc19bdb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T5 loaded!\n",
      "\n",
      "======================================================================\n",
      "‚ú® Smart T5 Audio Summarizer Ready!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üéØ SMART T5 AUDIO SUMMARIZER\n",
      "======================================================================\n",
      "\n",
      "üéµ Audio: Mumma xray review BH neurosurgeon.m4a (2.01 MB)\n",
      "‚è≥ Transcribing...\n",
      "\n",
      "Detected language: Hindi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24925/24925 [02:40<00:00, 155.51frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transcription complete!\n",
      "üåç Language: Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)\n",
      "üìù Words: 1092\n",
      "üß† Calculating adaptive summary length...\n",
      "üìä Strategy: COMPREHENSIVE\n",
      "üìù Description: Extensive detail\n",
      "üìè Input: 1092 words\n",
      "üìè Target: 262-450 words\n",
      "üìâ Compression: 57%\n",
      "‚ö° Quality: BEST\n",
      "\n",
      "üìä Generating T5 summary (process_audio_smart)...\n",
      "  üìÑ Processing 3 chunk(s)...\n",
      "    ‚û§ Chunk 1/3 (400 words)... ‚úì\n",
      "    ‚û§ Chunk 2/3 (400 words)... ‚úì\n",
      "    ‚û§ Chunk 3/3 (292 words)... ‚úì\n",
      "‚úÖ Summary generated! (337 words)\n",
      "\n",
      "======================================================================\n",
      "üìã RESULTS\n",
      "======================================================================\n",
      "üìÅ File: Mumma xray review BH neurosurgeon.m4a\n",
      "üåç Language: Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)\n",
      "üìä strategy: COMPREHENSIVE\n",
      "‚ö° Quality: BEST\n",
      "üìè Original: 1092 words\n",
      "üìè Summary: 337 words\n",
      "üìâ Compression: 69.1%\n",
      "\n",
      "======================================================================\n",
      "‚ú® T5 ABSTRACTIVE SUMMARY:\n",
      "======================================================================\n",
      "summarize: We had come here on Tuesday and the doctor had referred us for X-ray and this is today's baby. This was from that day and these are her medicines. This is the Prega and Medcoba which is a combination of medicines. Yes, this is the combination. But because of this, she is feeling very sleepy and her head is becoming very heavy. Do we eat in the night or we can eat a little earlier? No, no. There is only one medicine specialist. He is wearing a Kaaba. Why? Ma'am had recommended it. Who recommended it? It is for the nerves. It is tonic for the nervous. So, we have to eat half an hour before going to sleep. One or two hours will be fine. summarize: double dose. He is taking a double dose and he is going to take another double dose of the same medicine, but this time he's going to be taking two doses of the drug, which he hasn't been taking in a long time, because he doesn't know how to take it. He's not going to go to the doctor and ask for a second dose, because that's what his doctor told him to do, and if he does, he won't be able to get the second dose until he gets home from the doctor's office, and then he will have to go back to the hospital where he got the first dose, so he might as well go to a hospital. Taking a double dose. He is taking a Double Dose of Xanax, a drug that has been shown to reduce the risk of heart attacks and strokes in patients with high blood pressure, high cholesterol, diabetes, hypertension, and hyperlipidemia. It is also used to treat glaucoma, which is a condition in which the arteries become narrowed and the blood vessels constrict, reducing blood flow to the heart and preventing blood clots, which can lead to heart attack and stroke. It has also been found to lower blood pressure.\n",
      "\n",
      "======================================================================\n",
      "üìÑ FULL TRANSCRIPTION (first 400 chars):\n",
      "======================================================================\n",
      "We had come here on Tuesday and the doctor had referred us for X-ray and this is today's baby. This was from that day and these are her medicines. This is Prega and Medcoba which is a combination of medicines. This is the combination. Yes, this is the combination. But because of this, she is feeling very sleepy and her head is becoming very heavy. Do you eat in the night? Yes, we eat in the night....\n",
      "======================================================================\n",
      "\n",
      "üíæ Saved to: /kaggle/working/Summary_google_flan-t5-large_comprehensive_best-random-meeting.txt\n",
      "\n",
      "Saving output to: /kaggle/working/Summary_google_flan-t5-large_comprehensive_best-random-meeting.txt\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 1: GENERATE BRD FROM AUDIO\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "AUDIO TO BRD CONVERTER\n",
      "======================================================================\n",
      "\n",
      "STEP 3: Extracting structured information...\n",
      "STEP 4: Generating BRD...\n",
      "\n",
      "‚úÖ BRD generated and saved!\n",
      "üìÅ File: /kaggle/working/brd_Mobile_App_Redesign.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 2: GENERATE PURCHASE ORDER FROM AUDIO\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "AUDIO TO PURCHASE_ORDER CONVERTER\n",
      "======================================================================\n",
      "\n",
      "STEP 3: Extracting structured information...\n",
      "STEP 4: Generating PURCHASE_ORDER...\n",
      "\n",
      "‚úÖ PURCHASE_ORDER generated and saved!\n",
      "üìÅ File: /kaggle/working/purchase_order_Mumma xray review BH neurosurgeon.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# USAGE EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "# Clear memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  \n",
    "\n",
    "import gc\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 1: Load Models ONCE\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    #  Audio --- Sumamry --- Document\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INITIALIZING T5 LARGE DOCUMENT GENERATOR\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "    summarizer = SmartT5LargeDocumentGenerator(\n",
    "        whisper_model=\"large\",\n",
    "        t5_model=\"google/flan-t5-large\"  # Instruction-tuned T5\n",
    "        )\n",
    "\n",
    "    audio_path=\"/kaggle/input/eng-hinbi-marathi-mix-audio/Aao na.m4a\"\n",
    "    \n",
    "   # Create a unique filename using the current strategy name in the loop.\n",
    "    # We use .replace('_', '-') for cleaner filenames if needed, but it works fine as is.\n",
    "    t5_model=\"google/flan-t5-large\"\n",
    "    strategy=\"comprehensive\"\n",
    "    quality=\"best\"\n",
    "    safe_model_name = t5_model.replace('/', '_') \n",
    "    dynamic_output_filename = f\"Summary_{safe_model_name}_{strategy}_{quality}-random-meeting.txt\"\n",
    "    # === END DYNAMIC FILENAME CHANGE ===\n",
    "\n",
    "    results = summarizer.process_audio_smart(\n",
    "        audio_path = audio_path,\n",
    "        strategy=\"comprehensive\",\n",
    "        quality=\"best\", \n",
    "        save_output=True,\n",
    "        output_filename=dynamic_output_filename\n",
    "        )\n",
    "\n",
    "    print(f\"Saving output to: /kaggle/working/{dynamic_output_filename}\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # EXAMPLE 1: Generate BRD from Audio\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 1: GENERATE BRD FROM AUDIO\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    brd_output_filename = f\"Summary_{safe_model_name}_{strategy}_{quality}_brd-random-meeting.txt\"\n",
    "    \n",
    "    \n",
    "    brd_results = summarizer.process_audio_to_document(\n",
    "        audio_path=audio_path,\n",
    "        summary_text=results['summary'],\n",
    "        document_type='brd',\n",
    "        custom_instruction=\"Extract all business requirements, decisions, timeline, and stakeholder information\",\n",
    "        metadata={\n",
    "            'project_name': 'Mobile_App_Redesign',\n",
    "            'version': '1.0',\n",
    "            'status': 'Draft',\n",
    "            'author': 'Business Analysis Team',\n",
    "            'department': 'Product Development',\n",
    "            'sponsor': 'VP of Product',\n",
    "            'priority': 'High'\n",
    "        },\n",
    "        save_output=True,\n",
    "        output_filename=brd_output_filename\n",
    "    )\n",
    "    \n",
    "    #print(\"BRD Summary Preview:\")\n",
    "    #print(brd_results['summary_text'][:300] + \"...\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # EXAMPLE 2: Generate Purchase Order from Audio\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 2: GENERATE PURCHASE ORDER FROM AUDIO\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    po_output_filename = f\"Summary_{safe_model_name}_{strategy}_{quality}_po-random-meeting.txt\"\n",
    "\n",
    "    po_results = summarizer.process_audio_to_document(\n",
    "        audio_path=audio_path,\n",
    "        summary_text=results['summary'],\n",
    "        document_type='purchase_order',\n",
    "        custom_instruction=\"Extract vendor details, items to be purchased, quantities, costs, and delivery terms\",\n",
    "        metadata={\n",
    "            'po_number': 'PO-2024-001',\n",
    "            'vendor_name': 'ABC Technology Solutions Pvt Ltd',\n",
    "            'vendor_address': '123 Tech Park, Bangalore',\n",
    "            'vendor_contact': 'Mr. Rajesh Kumar',\n",
    "            'vendor_phone': '+91 98765 43210',\n",
    "            'vendor_email': 'rajesh@abctech.com',\n",
    "            'vendor_gst': '29ABCDE1234F1Z5',\n",
    "            'company_name': 'XYZ Enterprises Ltd',\n",
    "            'department': 'IT Procurement',\n",
    "            'payment_terms': 'Net 30 Days',\n",
    "            'delivery_date': '2024-02-15',\n",
    "            'shipping_method': 'Express Delivery',\n",
    "            'tax_rate': '18'\n",
    "        },\n",
    "        save_output=True,\n",
    "        output_filename=po_output_filename\n",
    "    )\n",
    "    \n",
    "    #print(\"PO Summary Preview:\")\n",
    "    #print(po_results['summary_text'][:300] + \"...\\n\")\n",
    "    \n",
    "    \n",
    "# Clear memory after processing\n",
    "    del results\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUSTOM INSTRUCTION EXAMPLES FOR FLAN-T5\n",
    "# ============================================================================\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "üí° CUSTOM INSTRUCTION IDEAS (for FLAN-T5):\n",
    "\n",
    "General:\n",
    "- \"Summarize the main points\"\n",
    "- \"Provide a brief overview\"\n",
    "- \"Extract the key information\"\n",
    "\n",
    "Business:\n",
    "- \"Summarize the key business decisions and action items\"\n",
    "- \"List the main discussion points from this meeting\"\n",
    "- \"What are the important takeaways for stakeholders?\"\n",
    "\n",
    "Educational:\n",
    "- \"Summarize the main concepts taught in this lecture\"\n",
    "- \"What are the key learning objectives?\"\n",
    "- \"Provide a student-friendly summary\"\n",
    "\n",
    "Technical:\n",
    "- \"Summarize the technical approach and methodology\"\n",
    "- \"What are the main technical challenges discussed?\"\n",
    "- \"Extract the implementation details\"\n",
    "\n",
    "News/Media:\n",
    "- \"Summarize who, what, when, where, and why\"\n",
    "- \"What is the main story and its impact?\"\n",
    "- \"Provide a headline-style summary\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# T5 MODEL QUICK REFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "üìö T5 MODEL GUIDE:\n",
    "\n",
    "1. t5-small (60M params)\n",
    "   - Fastest\n",
    "   - Good for short audio (<5 min)\n",
    "   - Lower quality\n",
    "   - Best for: Quick tests, resource-limited\n",
    "\n",
    "2. t5-base (220M params) ‚Üê RECOMMENDED\n",
    "   - Balanced speed/quality\n",
    "   - Works for any audio length\n",
    "   - Best general-purpose choice\n",
    "   - Best for: Most use cases\n",
    "\n",
    "3. t5-large (770M params)\n",
    "   - High quality\n",
    "   - Slower\n",
    "   - Requires more GPU memory\n",
    "   - Best for: Quality-critical tasks\n",
    "\n",
    "4. google/flan-t5-base (220M params) ‚Üê BEST FOR INSTRUCTIONS\n",
    "   - Instruction-tuned version\n",
    "   - Works with custom instructions\n",
    "   - Better understanding of context\n",
    "   - Best for: Specific summarization goals\n",
    "\n",
    "5. google/flan-t5-large (770M params)\n",
    "   - Best quality with instructions\n",
    "   - Excellent context understanding\n",
    "   - Slower, needs good GPU\n",
    "   - Best for: Professional applications\n",
    "\n",
    "‚ö° SPEED COMPARISON (relative):\n",
    "t5-small: 1x\n",
    "t5-base: 2.5x\n",
    "t5-large: 8x\n",
    "flan-t5-base: 2.5x\n",
    "flan-t5-large: 8x\n",
    "\n",
    "üíæ MEMORY USAGE:\n",
    "t5-small: ~300 MB\n",
    "t5-base: ~900 MB\n",
    "t5-large: ~3 GB\n",
    "flan-t5-base: ~900 MB\n",
    "flan-t5-large: ~3 GB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary to BRD / PO\n",
    "\n",
    "How It Works\n",
    "\n",
    "Audio ‚Üí Transcription (Whisper)\n",
    "Transcription ‚Üí Summary (T5)\n",
    "Summary ‚Üí Structured Sections (NLP extraction)\n",
    "Sections ‚Üí Formatted Document (Template formatting)\n",
    "\n",
    "The formatter automatically extracts:\n",
    "\n",
    "Requirements (words: require, need, must, should)\n",
    "Decisions (words: decide, agreed, approved)\n",
    "Action Items (words: will, task, assign, responsible)\n",
    "Timeline (words: deadline, date, week, month)\n",
    "Budget (words: cost, budget, price, payment)\n",
    "Risks (words: risk, concern, issue, challenge)\n",
    "Technical (words: technical, system, platform, API)\n",
    "\n",
    " Tips for Best Results\n",
    "\n",
    "Use comprehensive/detailed strategy for documents\n",
    "Provide metadata for professional formatting\n",
    "Process once, save multiple formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T12:12:42.822050Z",
     "iopub.status.busy": "2026-01-19T12:12:42.821817Z",
     "iopub.status.idle": "2026-01-19T12:12:42.825099Z",
     "shell.execute_reply": "2026-01-19T12:12:42.824566Z",
     "shell.execute_reply.started": "2026-01-19T12:12:42.822029Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# following code in markdown: Full audio to brd / po using above code, will take modules from this code and add it \n",
    "# to abv code and save it as version 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Smart T5 Large Audio to Professional Documents Converter\n",
    "Uses: Whisper Large + FLAN-T5-Large\n",
    "Outputs: BRD, Purchase Order, and other business documents\n",
    "Optimized for Kaggle with GPU acceleration\n",
    "\"\"\"\n",
    "\n",
    "import whisper\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# INSTALLATION (Run in Kaggle first cell):\n",
    "# !pip install -q openai-whisper transformers sentencepiece accelerate\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class SmartT5LargeDocumentGenerator:\n",
    "    \"\"\"\n",
    "    Complete pipeline: Audio ‚Üí T5 Large Summary ‚Üí Professional Documents\n",
    "    Handles: BRD, Purchase Orders, Meeting Minutes, Technical Specs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, whisper_model=\"large\", t5_model=\"google/flan-t5-large\"):\n",
    "        \"\"\"\n",
    "        Initialize with LARGE models for highest quality\n",
    "        \n",
    "        Args:\n",
    "            whisper_model: 'large' for best transcription\n",
    "            t5_model: 'google/flan-t5-large' for best summarization\n",
    "        \"\"\"\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        if self.device == \"cpu\":\n",
    "            print(\"‚ö†Ô∏è  WARNING: Running on CPU will be VERY SLOW!\")\n",
    "            print(\"   Enable GPU in Kaggle: Settings ‚Üí Accelerator ‚Üí GPU T4 x2\\n\")\n",
    "        \n",
    "        print(f\"üîß Device: {self.device}\")\n",
    "        if self.device == \"cuda\":\n",
    "            print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            print(f\"üíæ GPU Memory: {gpu_memory:.2f} GB\")\n",
    "        \n",
    "        # Load Whisper Large\n",
    "        print(f\"\\nüì• Loading Whisper Large...\")\n",
    "        self.whisper_model = whisper.load_model(whisper_model, device=self.device)\n",
    "        print(\"‚úÖ Whisper Large loaded!\")\n",
    "        \n",
    "        # Load FLAN-T5 Large\n",
    "        print(f\"\\nüì• Loading FLAN-T5 Large...\")\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(t5_model, legacy=False)\n",
    "        \n",
    "        if self.device == \"cuda\":\n",
    "            self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "                t5_model,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "        else:\n",
    "            self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "                t5_model,\n",
    "                torch_dtype=torch.float32\n",
    "            ).to(self.device)\n",
    "        \n",
    "        print(\"‚úÖ FLAN-T5 Large loaded!\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚ú® Smart T5 Large Document Generator Ready!\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    def transcribe_audio(self, audio_path):\n",
    "        \"\"\"Transcribe audio with Whisper Large\"\"\"\n",
    "        \n",
    "        if not os.path.exists(audio_path):\n",
    "            raise FileNotFoundError(f\"‚ùå File not found: {audio_path}\")\n",
    "        \n",
    "        file_size = os.path.getsize(audio_path) / (1024 * 1024)\n",
    "        print(f\"üéµ Audio: {os.path.basename(audio_path)} ({file_size:.2f} MB)\")\n",
    "        print(f\"‚è≥ Transcribing with Whisper Large...\\n\")\n",
    "        \n",
    "        result = self.whisper_model.transcribe(\n",
    "            audio_path,\n",
    "            task='translate',\n",
    "            language=None,\n",
    "            fp16=self.device == \"cuda\",\n",
    "            verbose=False,\n",
    "            beam_size=5,\n",
    "            best_of=5,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        lang_map = {\n",
    "            'hi': 'Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)',\n",
    "            'en': 'English',\n",
    "            'mr': 'Marathi (‡§Æ‡§∞‡§æ‡§†‡•Ä)'\n",
    "        }\n",
    "        \n",
    "        detected = result.get('language', 'unknown')\n",
    "        text = result['text'].strip()\n",
    "        word_count = len(text.split())\n",
    "        \n",
    "        print(f\"‚úÖ Transcription complete!\")\n",
    "        print(f\"üåç Language: {lang_map.get(detected, detected)}\")\n",
    "        print(f\"üìù Words: {word_count}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'language': lang_map.get(detected, detected),\n",
    "            'word_count': word_count\n",
    "        }\n",
    "    \n",
    "    def generate_summary(self, text, custom_instruction=None, max_length=512):\n",
    "        \"\"\"Generate summary with FLAN-T5 Large\"\"\"\n",
    "        \n",
    "        print(f\"üìä Generating high-quality summary with FLAN-T5 Large...\")\n",
    "        \n",
    "        # Prepare instruction\n",
    "        if custom_instruction:\n",
    "            input_text = f\"{custom_instruction}: {text}\"\n",
    "        else:\n",
    "            input_text = f\"Provide a comprehensive summary including key points, decisions, requirements, and action items: {text}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            summary_ids = self.model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_length=max_length,\n",
    "                min_length=max_length // 4,\n",
    "                num_beams=8,\n",
    "                length_penalty=1.8,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=4,\n",
    "                repetition_penalty=1.3,\n",
    "                temperature=1.0,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        summary = self.tokenizer.decode(\n",
    "            summary_ids[0],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Summary generated: {len(summary.split())} words\\n\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def extract_structured_info(self, summary_text):\n",
    "        \"\"\"Extract structured information from summary\"\"\"\n",
    "        \n",
    "        info = {\n",
    "            'requirements': [],\n",
    "            'decisions': [],\n",
    "            'action_items': [],\n",
    "            'timeline': [],\n",
    "            'budget': [],\n",
    "            'risks': [],\n",
    "            'technical': [],\n",
    "            'deliverables': [],\n",
    "            'stakeholders': []\n",
    "        }\n",
    "        \n",
    "        sentences = re.split(r'[.!?]+', summary_text)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "            \n",
    "            lower = sentence.lower()\n",
    "            \n",
    "            # Requirements\n",
    "            if any(w in lower for w in ['require', 'need', 'must', 'should', 'shall', 'expect']):\n",
    "                info['requirements'].append(sentence)\n",
    "            \n",
    "            # Decisions\n",
    "            if any(w in lower for w in ['decide', 'agreed', 'approved', 'confirmed', 'finalized']):\n",
    "                info['decisions'].append(sentence)\n",
    "            \n",
    "            # Action items\n",
    "            if any(w in lower for w in ['will', 'task', 'action', 'assign', 'responsible', 'owner']):\n",
    "                info['action_items'].append(sentence)\n",
    "            \n",
    "            # Timeline\n",
    "            if any(w in lower for w in ['deadline', 'timeline', 'date', 'week', 'month', 'schedule', 'due']):\n",
    "                info['timeline'].append(sentence)\n",
    "            \n",
    "            # Budget\n",
    "            if any(w in lower for w in ['cost', 'budget', 'price', 'payment', 'fund', 'expense', '$', 'rs', 'rupee', 'inr']):\n",
    "                info['budget'].append(sentence)\n",
    "            \n",
    "            # Risks\n",
    "            if any(w in lower for w in ['risk', 'concern', 'issue', 'challenge', 'problem', 'blocker']):\n",
    "                info['risks'].append(sentence)\n",
    "            \n",
    "            # Technical\n",
    "            if any(w in lower for w in ['technical', 'technology', 'system', 'platform', 'api', 'database', 'infrastructure']):\n",
    "                info['technical'].append(sentence)\n",
    "            \n",
    "            # Deliverables\n",
    "            if any(w in lower for w in ['deliver', 'output', 'product', 'feature', 'component', 'milestone']):\n",
    "                info['deliverables'].append(sentence)\n",
    "            \n",
    "            # Stakeholders\n",
    "            if any(w in lower for w in ['stakeholder', 'team', 'department', 'client', 'customer', 'vendor']):\n",
    "                info['stakeholders'].append(sentence)\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def generate_brd(self, summary_text, structured_info, metadata):\n",
    "        \"\"\"Generate Business Requirements Document\"\"\"\n",
    "        \n",
    "        doc = f\"\"\"\n",
    "{'='*80}\n",
    "BUSINESS REQUIREMENTS DOCUMENT (BRD)\n",
    "{'='*80}\n",
    "\n",
    "Document Information:\n",
    "--------------------\n",
    "Project Name:     {metadata.get('project_name', 'Audio Extracted Project')}\n",
    "Document Date:    {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\n",
    "Version:          {metadata.get('version', '1.0')}\n",
    "Prepared By:      {metadata.get('author', 'T5 Large Audio Analysis System')}\n",
    "Status:           {metadata.get('status', 'Draft - Extracted from Audio')}\n",
    "Department:       {metadata.get('department', 'TBD')}\n",
    "Sponsor:          {metadata.get('sponsor', 'TBD')}\n",
    "\n",
    "\n",
    "1. EXECUTIVE SUMMARY\n",
    "{'='*80}\n",
    "\n",
    "{summary_text}\n",
    "\n",
    "\n",
    "2. BUSINESS OBJECTIVES\n",
    "{'='*80}\n",
    "\n",
    "Based on the audio discussion, the key business objectives are:\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Add objectives from summary\n",
    "        if structured_info['requirements']:\n",
    "            for idx, req in enumerate(structured_info['requirements'][:5], 1):\n",
    "                doc += f\"OBJ-{idx}: {req}\\n\"\n",
    "        else:\n",
    "            doc += \"Business objectives to be refined based on stakeholder review.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "3. BUSINESS REQUIREMENTS\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['requirements']:\n",
    "            for idx, req in enumerate(structured_info['requirements'], 1):\n",
    "                doc += f\"BR-{idx:03d}: {req}\\n\"\n",
    "                doc += f\"         Priority: {metadata.get('priority', 'Medium')}\\n\"\n",
    "                doc += f\"         Status: New\\n\"\n",
    "                doc += f\"         Source: Audio Discussion\\n\\n\"\n",
    "        else:\n",
    "            doc += \"Business requirements extracted from executive summary above.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "4. FUNCTIONAL REQUIREMENTS\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['technical']:\n",
    "            for idx, tech in enumerate(structured_info['technical'], 1):\n",
    "                doc += f\"FR-{idx:03d}: {tech}\\n\"\n",
    "                doc += f\"         Category: {metadata.get('category', 'Technical')}\\n\"\n",
    "                doc += f\"         Priority: {metadata.get('priority', 'Medium')}\\n\\n\"\n",
    "        else:\n",
    "            doc += \"Functional requirements to be detailed in technical specification.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "5. STAKEHOLDERS\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['stakeholders']:\n",
    "            doc += \"Stakeholders identified in discussion:\\n\\n\"\n",
    "            for stakeholder in structured_info['stakeholders']:\n",
    "                doc += f\"‚Ä¢ {stakeholder}\\n\"\n",
    "        else:\n",
    "            doc += f\"\"\"\n",
    "Primary Stakeholders:\n",
    "‚Ä¢ Project Sponsor: {metadata.get('sponsor', 'TBD')}\n",
    "‚Ä¢ Business Owner: {metadata.get('business_owner', 'TBD')}\n",
    "‚Ä¢ Project Manager: {metadata.get('pm', 'TBD')}\n",
    "‚Ä¢ End Users: {metadata.get('end_users', 'As discussed in audio')}\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "6. KEY DECISIONS\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['decisions']:\n",
    "            for idx, decision in enumerate(structured_info['decisions'], 1):\n",
    "                doc += f\"D{idx}. {decision}\\n\"\n",
    "                doc += f\"    Date: {metadata.get('date', 'TBD')}\\n\"\n",
    "                doc += f\"    Decision Maker: {metadata.get('decision_maker', 'TBD')}\\n\\n\"\n",
    "        else:\n",
    "            doc += \"Key decisions documented in executive summary.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "7. SCOPE\n",
    "{'='*80}\n",
    "\n",
    "In Scope:\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['deliverables']:\n",
    "            for deliverable in structured_info['deliverables']:\n",
    "                doc += f\"‚Ä¢ {deliverable}\\n\"\n",
    "        else:\n",
    "            doc += \"‚Ä¢ As defined in requirements above\\n\"\n",
    "        \n",
    "        doc += \"\"\"\n",
    "\n",
    "Out of Scope:\n",
    "‚Ä¢ Items not mentioned in the audio discussion\n",
    "‚Ä¢ Features to be considered for future phases\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "8. TIMELINE & MILESTONES\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['timeline']:\n",
    "            for milestone in structured_info['timeline']:\n",
    "                doc += f\"‚Ä¢ {milestone}\\n\"\n",
    "        else:\n",
    "            doc += f\"\"\"\n",
    "Project Timeline:\n",
    "‚Ä¢ Requirements Phase: {metadata.get('req_phase', 'TBD')}\n",
    "‚Ä¢ Design Phase: {metadata.get('design_phase', 'TBD')}\n",
    "‚Ä¢ Development Phase: {metadata.get('dev_phase', 'TBD')}\n",
    "‚Ä¢ Testing Phase: {metadata.get('test_phase', 'TBD')}\n",
    "‚Ä¢ Deployment: {metadata.get('deployment', 'TBD')}\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "9. BUDGET & RESOURCES\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['budget']:\n",
    "            for budget_item in structured_info['budget']:\n",
    "                doc += f\"‚Ä¢ {budget_item}\\n\"\n",
    "        else:\n",
    "            doc += f\"\"\"\n",
    "Estimated Budget: {metadata.get('budget', 'To be determined')}\n",
    "\n",
    "Resource Requirements:\n",
    "‚Ä¢ Team Size: {metadata.get('team_size', 'TBD')}\n",
    "‚Ä¢ Duration: {metadata.get('duration', 'TBD')}\n",
    "‚Ä¢ External Resources: {metadata.get('external_resources', 'TBD')}\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "10. RISKS & ASSUMPTIONS\n",
    "{'='*80}\n",
    "\n",
    "Risks Identified:\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['risks']:\n",
    "            for idx, risk in enumerate(structured_info['risks'], 1):\n",
    "                doc += f\"{idx}. {risk}\\n\"\n",
    "                doc += f\"   Impact: {metadata.get('risk_impact', 'Medium')}\\n\"\n",
    "                doc += f\"   Mitigation: To be defined\\n\\n\"\n",
    "        else:\n",
    "            doc += \"Risk assessment to be conducted during project planning.\\n\"\n",
    "        \n",
    "        doc += \"\"\"\n",
    "\n",
    "Assumptions:\n",
    "‚Ä¢ Resources will be available as per project timeline\n",
    "‚Ä¢ Stakeholder approvals will be obtained in timely manner\n",
    "‚Ä¢ Technical infrastructure is available and ready\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "11. DEPENDENCIES\n",
    "{'='*80}\n",
    "\n",
    "‚Ä¢ Dependencies identified in audio discussion\n",
    "‚Ä¢ External systems and integrations as required\n",
    "‚Ä¢ Third-party services and vendors as needed\n",
    "\n",
    "\n",
    "12. SUCCESS CRITERIA\n",
    "{'='*80}\n",
    "\n",
    "The project will be considered successful when:\n",
    "\n",
    "‚Ä¢ All business requirements are met\n",
    "‚Ä¢ System is deployed and operational\n",
    "‚Ä¢ User acceptance testing is completed successfully\n",
    "‚Ä¢ Stakeholders sign off on deliverables\n",
    "\n",
    "\n",
    "13. APPROVAL\n",
    "{'='*80}\n",
    "\n",
    "This document has been reviewed and approved by:\n",
    "\n",
    "\n",
    "Business Owner: _____________________    Date: ___________\n",
    "\n",
    "Signature:      _____________________\n",
    "\n",
    "\n",
    "Project Sponsor: ____________________    Date: ___________\n",
    "\n",
    "Signature:       ____________________\n",
    "\n",
    "\n",
    "{'='*80}\n",
    "Document Generated from Audio Analysis using Whisper Large + FLAN-T5 Large\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "        \n",
    "        return doc\n",
    "    \n",
    "    def generate_purchase_order(self, summary_text, structured_info, metadata):\n",
    "        \"\"\"Generate Purchase Order\"\"\"\n",
    "        \n",
    "        doc = f\"\"\"\n",
    "{'='*80}\n",
    "PURCHASE ORDER\n",
    "{'='*80}\n",
    "\n",
    "PO Number:        {metadata.get('po_number', 'PO-' + datetime.now().strftime('%Y%m%d-%H%M'))}\n",
    "Date:             {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\n",
    "Status:           {metadata.get('status', 'Draft - Extracted from Audio')}\n",
    "\n",
    "\n",
    "VENDOR INFORMATION:\n",
    "{'='*80}\n",
    "Vendor Name:      {metadata.get('vendor_name', 'TBD - As per audio discussion')}\n",
    "Vendor Code:      {metadata.get('vendor_code', 'TBD')}\n",
    "Address:          {metadata.get('vendor_address', 'TBD')}\n",
    "City/State/ZIP:   {metadata.get('vendor_location', 'TBD')}\n",
    "Contact Person:   {metadata.get('vendor_contact', 'TBD')}\n",
    "Phone:            {metadata.get('vendor_phone', 'TBD')}\n",
    "Email:            {metadata.get('vendor_email', 'TBD')}\n",
    "GST/Tax ID:       {metadata.get('vendor_gst', 'TBD')}\n",
    "\n",
    "\n",
    "BUYER INFORMATION:\n",
    "{'='*80}\n",
    "Company Name:     {metadata.get('company_name', 'Your Company Ltd.')}\n",
    "Department:       {metadata.get('department', 'Procurement')}\n",
    "Address:          {metadata.get('buyer_address', 'TBD')}\n",
    "City/State/ZIP:   {metadata.get('buyer_location', 'TBD')}\n",
    "Contact Person:   {metadata.get('buyer_contact', metadata.get('author', 'TBD'))}\n",
    "Phone:            {metadata.get('buyer_phone', 'TBD')}\n",
    "Email:            {metadata.get('buyer_email', 'TBD')}\n",
    "\n",
    "\n",
    "PURCHASE ORDER SUMMARY:\n",
    "{'='*80}\n",
    "\n",
    "Based on Audio Discussion:\n",
    "{summary_text}\n",
    "\n",
    "\n",
    "DETAILED LINE ITEMS:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Extract items from deliverables or requirements\n",
    "        items = structured_info['deliverables'] if structured_info['deliverables'] else structured_info['requirements']\n",
    "        \n",
    "        doc += f\"{'Item':<5} {'Description':<45} {'Qty':<8} {'Unit':<10} {'Price':<12} {'Total':<12}\\n\"\n",
    "        doc += \"-\" * 100 + \"\\n\"\n",
    "        \n",
    "        if items:\n",
    "            for idx, item in enumerate(items[:15], 1):  # Max 15 items\n",
    "                clean_item = item.replace('\\n', ' ')[:42]\n",
    "                doc += f\"{idx:<5} {clean_item:<45} {'TBD':<8} {'Each':<10} {'TBD':<12} {'TBD':<12}\\n\"\n",
    "        else:\n",
    "            doc += f\"{'1':<5} {'Items/Services as per audio discussion':<45} {'TBD':<8} {'Each':<10} {'TBD':<12} {'TBD':<12}\\n\"\n",
    "        \n",
    "        doc += \"\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "COST BREAKDOWN:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['budget']:\n",
    "            doc += \"Cost Details (from audio discussion):\\n\\n\"\n",
    "            for budget_item in structured_info['budget']:\n",
    "                doc += f\"‚Ä¢ {budget_item}\\n\"\n",
    "            doc += \"\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "Subtotal:                                                    {metadata.get('subtotal', 'TBD')}\n",
    "Discount (if any):                                           {metadata.get('discount', '0.00')}\n",
    "                                                             ___________\n",
    "Subtotal after Discount:                                     {metadata.get('subtotal_after_discount', 'TBD')}\n",
    "\n",
    "Tax/GST ({metadata.get('tax_rate', '18')}%):                                             {metadata.get('tax_amount', 'TBD')}\n",
    "Shipping & Handling:                                         {metadata.get('shipping', 'TBD')}\n",
    "Other Charges:                                               {metadata.get('other_charges', '0.00')}\n",
    "                                                             ___________\n",
    "TOTAL AMOUNT:                                                {metadata.get('total_amount', 'TBD')}\n",
    "                                                             ===========\n",
    "\n",
    "\n",
    "TERMS & CONDITIONS:\n",
    "{'='*80}\n",
    "\n",
    "Payment Terms:         {metadata.get('payment_terms', 'Net 30 Days')}\n",
    "Delivery Terms:        {metadata.get('delivery_terms', 'FOB Destination')}\n",
    "Expected Delivery:     {metadata.get('delivery_date', 'TBD - As per discussion')}\n",
    "Delivery Address:      {metadata.get('delivery_address', 'As per buyer information above')}\n",
    "Shipping Method:       {metadata.get('shipping_method', 'Standard')}\n",
    "Warranty:              {metadata.get('warranty', 'As per vendor terms')}\n",
    "Return Policy:         {metadata.get('return_policy', 'As per vendor terms')}\n",
    "\n",
    "\n",
    "PAYMENT SCHEDULE:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if metadata.get('payment_schedule'):\n",
    "            doc += metadata['payment_schedule']\n",
    "        else:\n",
    "            doc += f\"\"\"\n",
    "‚Ä¢ Advance Payment: {metadata.get('advance_payment', '0%')} on PO confirmation\n",
    "‚Ä¢ Balance Payment: {metadata.get('balance_payment', '100%')} {metadata.get('payment_terms', 'Net 30')}\n",
    "\"\"\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "SPECIAL INSTRUCTIONS:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['requirements']:\n",
    "            doc += \"Requirements from audio discussion:\\n\\n\"\n",
    "            for req in structured_info['requirements'][:5]:\n",
    "                doc += f\"‚Ä¢ {req}\\n\"\n",
    "        else:\n",
    "            doc += \"As per audio discussion and mutual agreement.\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "ADDITIONAL NOTES:\n",
    "{'='*80}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if structured_info['action_items']:\n",
    "            doc += \"Action Items:\\n\\n\"\n",
    "            for action in structured_info['action_items'][:5]:\n",
    "                doc += f\"‚Ä¢ {action}\\n\"\n",
    "        \n",
    "        doc += f\"\"\"\n",
    "\n",
    "VALIDITY:\n",
    "{'='*80}\n",
    "\n",
    "This Purchase Order is valid until: {metadata.get('validity_date', 'TBD')}\n",
    "\n",
    "\n",
    "APPROVAL & AUTHORIZATION:\n",
    "{'='*80}\n",
    "\n",
    "Requested By:\n",
    "\n",
    "Name:      {metadata.get('requested_by', 'TBD')}\n",
    "Title:     {metadata.get('requested_title', 'TBD')}\n",
    "Date:      {metadata.get('date', 'TBD')}\n",
    "Signature: _____________________\n",
    "\n",
    "\n",
    "Approved By:\n",
    "\n",
    "Name:      {metadata.get('approved_by', 'TBD')}\n",
    "Title:     {metadata.get('approved_title', 'Manager/Director')}\n",
    "Date:      ___________\n",
    "Signature: _____________________\n",
    "\n",
    "\n",
    "Finance Approval:\n",
    "\n",
    "Name:      {metadata.get('finance_approval', 'TBD')}\n",
    "Title:     Finance Manager\n",
    "Date:      ___________\n",
    "Signature: _____________________\n",
    "\n",
    "\n",
    "VENDOR ACCEPTANCE:\n",
    "{'='*80}\n",
    "\n",
    "We accept the terms and conditions of this Purchase Order:\n",
    "\n",
    "Vendor Name:    {metadata.get('vendor_name', 'TBD')}\n",
    "Authorized By:  _____________________\n",
    "Title:          _____________________\n",
    "Date:           ___________\n",
    "Signature:      _____________________\n",
    "Company Seal:   \n",
    "\n",
    "\n",
    "{'='*80}\n",
    "Purchase Order Generated from Audio Analysis\n",
    "System: Whisper Large + FLAN-T5 Large\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'='*80}\n",
    "\n",
    "IMPORTANT NOTES:\n",
    "- This is a preliminary document extracted from audio discussion\n",
    "- Please review and verify all details before finalization\n",
    "- TBD items must be filled in before final approval\n",
    "- Consult legal/procurement team for compliance review\n",
    "\"\"\"\n",
    "        \n",
    "        return doc\n",
    "    \n",
    "    def process_audio_to_document(\n",
    "        self,\n",
    "        audio_path,\n",
    "        document_type='brd',\n",
    "        custom_instruction=None,\n",
    "        metadata=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Complete pipeline: Audio ‚Üí Summary ‚Üí Document\n",
    "        \n",
    "        Args:\n",
    "            audio_path: Path to audio file\n",
    "            document_type: 'brd' or 'purchase_order'\n",
    "            custom_instruction: Custom instruction for T5\n",
    "            metadata: Document metadata\n",
    "        \n",
    "        Returns:\n",
    "            dict with transcription, summary, and formatted document\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(f\"AUDIO TO {document_type.upper()} CONVERTER\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        # Step 1: Transcribe\n",
    "        print(\"STEP 1: Transcribing with Whisper Large...\")\n",
    "        transcription = self.transcribe_audio(audio_path)\n",
    "        \n",
    "        # Step 2: Generate Summary\n",
    "        print(\"STEP 2: Generating summary with FLAN-T5 Large...\")\n",
    "        summary = self.generate_summary(\n",
    "            transcription['text'],\n",
    "            custom_instruction=custom_instruction\n",
    "        )\n",
    "        \n",
    "        # Step 3: Extract structured information\n",
    "        print(\"STEP 3: Extracting structured information...\")\n",
    "        structured_info = self.extract_structured_info(summary)\n",
    "        \n",
    "        # Step 4: Generate document\n",
    "        print(f\"STEP 4: Generating {document_type.upper()}...\\n\")\n",
    "        \n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "        \n",
    "        metadata.setdefault('project_name', os.path.basename(audio_path).split('.')[0])\n",
    "        metadata.setdefault('date', datetime.now().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        if document_type == 'brd':\n",
    "            formatted_doc = self.generate_brd(summary, structured_info, metadata)\n",
    "        elif document_type == 'purchase_order':\n",
    "            formatted_doc = self.generate_purchase_order(summary, structured_info, metadata)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown document type: {document_type}\")\n",
    "        \n",
    "        # Step 5: Save\n",
    "        output_filename = f\"/kaggle/working/{document_type}_{metadata['project_name']}.txt\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(formatted_doc)\n",
    "        \n",
    "        print(f\"‚úÖ {document_type.upper()} generated and saved!\")\n",
    "        print(f\"üìÅ File: {output_filename}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'transcription': transcription['text'],\n",
    "            'summary': summary,\n",
    "            'structured_info': structured_info,\n",
    "            'formatted_document': formatted_doc,\n",
    "            'output_file': output_filename\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Load Models ONCE\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"INITIALIZING T5 LARGE DOCUMENT GENERATOR\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    generator = SmartT5LargeDocumentGenerator(\n",
    "        whisper_model=\"large\",\n",
    "        t5_model=\"google/flan-t5-large\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # EXAMPLE 1: Generate BRD from Audio\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 1: GENERATE BRD FROM AUDIO\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    brd_results = generator.process_audio_to_document(\n",
    "        audio_path=\"/kaggle/input/audio/requirements_meeting.mp3\",\n",
    "        document_type='brd',\n",
    "        custom_instruction=\"Extract all business requirements, decisions, timeline, and stakeholder information\",\n",
    "        metadata={\n",
    "            'project_name': 'Mobile_App_Redesign',\n",
    "            'version': '1.0',\n",
    "            'status': 'Draft',\n",
    "            'author': 'Business Analysis Team',\n",
    "            'department': 'Product Development',\n",
    "            'sponsor': 'VP of Product',\n",
    "            'priority': 'High'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"BRD Summary Preview:\")\n",
    "    print(brd_results['summary'][:300] + \"...\\n\")\n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # EXAMPLE 2: Generate Purchase Order from Audio\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 2: GENERATE PURCHASE ORDER FROM AUDIO\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    po_results = generator.process_audio_to_document(\n",
    "        audio_path=\"/kaggle/input/audio/vendor_discussion.mp3\",\n",
    "        document_type='purchase_order',\n",
    "        custom_instruction=\"Extract vendor details, items to be purchased, quantities, costs, and delivery terms\",\n",
    "        metadata={\n",
    "            'po_number': 'PO-2024-001',\n",
    "            'vendor_name': 'ABC Technology Solutions Pvt Ltd',\n",
    "            'vendor_address': '123 Tech Park, Bangalore',\n",
    "            'vendor_contact': 'Mr. Rajesh Kumar',\n",
    "            'vendor_phone': '+91 98765 43210',\n",
    "            'vendor_email': 'rajesh@abctech.com',\n",
    "            'vendor_gst': '29ABCDE1234F1Z5',\n",
    "            'company_name': 'XYZ Enterprises Ltd',\n",
    "            'department': 'IT Procurement',\n",
    "            'payment_terms': 'Net 30 Days',\n",
    "            'delivery_date': '2024-02-15',\n",
    "            'shipping_method': 'Express Delivery',\n",
    "            'tax_rate': '18'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"PO Summary Preview:\")\n",
    "    print(po_results['summary'][:300] + \"...\\n\")\n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # EXAMPLE 3: Process Multiple Audio Files\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 3: BATCH PROCESSING\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    audio_documents = [\n",
    "        {\n",
    "            'path': '/kaggle/input/audio/meeting1.mp3',\n",
    "            'type': 'brd',\n",
    "            'metadata': {'project_name': 'Project_Alpha', 'version': '1.0'}\n",
    "        },\n",
    "        {\n",
    "            'path': '/kaggle/input/audio/vendor_call.mp3',\n",
    "            'type': 'purchase_order',\n",
    "            'metadata': {'vendor_name': 'Vendor XYZ', 'po_number': 'PO-2024-002'}\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for item in audio_documents:\n",
    "        print(f\"\\nProcessing: {item['path']}\")\n",
    "        \n",
    "        try:\n",
    "            results = generator.process_audio_to_document(\n",
    "                audio_path=item['path'],\n",
    "                document_type=item['type'],\n",
    "                metadata=item['metadata']\n",
    "            )\n",
    "            all_results.append(results)\n",
    "            print(f\"‚úÖ Generated {item['type'].upper()}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\\n\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úÖ Batch processing complete! Generated {len(all_results)} documents.\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# COMPLETE WORKFLOW EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "COMPLETE WORKFLOW:\n",
    "\n",
    "# Cell 1: Installation\n",
    "!pip install -q openai-whisper transformers sentencepiece accelerate\n",
    "\n",
    "# Cell 2: Paste entire code above\n",
    "\n",
    "# Cell 3: Load models ONCE\n",
    "generator = SmartT5LargeDocumentGenerator(\n",
    "    whisper_model=\"large\",\n",
    "    t5_model=\"google/flan-t5-large\"\n",
    ")\n",
    "\n",
    "# Cell 4: Generate BRD\n",
    "brd = generator.process_audio_to"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8832408,
     "sourceId": 14547842,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
